# High-Level Feature Detection in Dictionary Learning (Ongoing Project)

This repository explores methods to rank and evaluate features generated by sparse autoencoders, focusing on conceptual depth and level of abstraction. Sparse autoencoders often produce thousands of features, making it challenging for researchers to identify the most relevant or high-level ones. This project aims to address this challenge by developing a metric to rank features by their conceptual depth, distinguishing between high-level abstract features and low-level concrete features.

This project intiially began as the application for Neel Nanda and Arthur Conmy's MATS stream. See original application doc [here](https://docs.google.com/document/d/1cMKdqVuVLYb6gjXb91fyInkiSa1dQ8oFUjnEgoBOMts/edit?usp=sharing).


## Background

Dictionary learning with sparse autoencoders can yield thousands of features. Current "auto-interp" methods label these features based on the samples that activate them. For instance, a feature might be labeled as "moon-related" if all activating samples reference the moon. However, even with descriptive labels, navigating and interpreting thousands of features remains a significant challenge.

A **high-level feature** represents abstract or semantically rich ideas, often activating across a diverse range of seemingly unrelated words or contexts. For example:
- **High-level feature:** *Sycophantic praise* or *Unrealistic beauty standards*.
- **Low-level feature:** *Golden Gate Bridge* or specific physical objects.

High-level features tend to activate on a variety of unrelated words, but their activations make sense within certain semantic contexts.

## Objectives

The goal of this project is to develop a metric to:
1. Rank features by their conceptual depth or level of abstraction.
2. Automate the detection of high-level features based on their activation patterns.

### Key Hypothesis
High-level features activate across diverse and seemingly unrelated words, which in isolation may not connect to the feature but do so within specific contexts.

## Methodology

1. **Feature Analysis:**
   - Identify features generated by sparse autoencoders.
   - Here we just use the features from the Gemma 2B model relased in Gemma Scope.

2. **Metric Development:**
   - Design a metric that evaluates the conceptual depth of a feature.
   - Incorporate activation patterns and semantic diversity into the metric.

3. **Validation:**
   - Test the metric on known datasets with labeled features.
   - Compare high-level vs. low-level feature rankings to human judgments.
